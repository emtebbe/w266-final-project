{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAG CORPUS CONSOLIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "#Import from custom w2v model file\n",
    "import w2v_model\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import itertools\n",
    "from itertools import chainimport torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import logging\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from scipy import stats, optimize\n",
    "import utils, vocabulary\n",
    "\n",
    "utils.require_package(\"tqdm\")  # for nice progress bars\n",
    "from tqdm import tqdm as ProgressBar\n",
    "\n",
    "# # Bokeh for plotting.\n",
    "utils.require_package(\"bokeh\")\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool\n",
    "bp.output_notebook()\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: SIMPLE EMBEDDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do:   \n",
    "use loss and test function to fine-tune embeddings \n",
    "add preprocessing notebook or keep it separate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define functions to retrieve tag data, preprocess the results, find similar embeddings, and introduce a functional suggestion test (inspired by masked-language-model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_start = time.time()\n",
    "\n",
    "lemma_list = []\n",
    "word_list = []\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def word_preprocessing(word):\n",
    "    lower = word.lower()\n",
    "    punct_replacer = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    rem_punct = lower.translate(punct_replacer)\n",
    "    lemma = [lemmatizer.lemmatize(w) for w in nltk.word_tokenize(rem_punct)]\n",
    "    rem_stop = [w for w in lemma if not w in stop_words]\n",
    "    rem_digits = [re.sub('\\d', '<dig>', i) for i in rem_stop]\n",
    "    lemma_list.append(rem_digits)\n",
    "    word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_matches(model, test_list):\n",
    "    \"\"\"\n",
    "    Given an embedding model and list of tags, gets most similar results based on Word2Vec embeddings \n",
    "    (model constructed in w2v_model.py).\n",
    "    Runs on one row (asset) at a time.\n",
    "    \"\"\"\n",
    "#     ref_list = []\n",
    "    matches = {}\n",
    "#     not_found = 0\n",
    "    for lstring in test_list:\n",
    "        tagset = []\n",
    "        try:\n",
    "            match = model.wv.most_similar(lstring)\n",
    "    #         print(ls, ' : ', match)\n",
    "#             ref_list.append(lstring)\n",
    "            for tag in range(len(match)):\n",
    "                tagset.append(match[tag][0])\n",
    "\n",
    "#             ref_list.append(tagset)\n",
    "            matches[lstring] = tagset\n",
    "        except KeyError:\n",
    "    #         print(ls, ' : ','NOT_FOUND')\n",
    "            pass\n",
    "#     print(\"Not found\", not_found)\n",
    "    return matches\n",
    "\n",
    "# search_list = ['blue']\n",
    "# get_top_matches(model, search_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_prediction(test_dictionary):\n",
    "    \"\"\"\n",
    "    Selects one random key from dictionary and determines if any values for that key\n",
    "    match any other keys in the dictionary (in other words, whether the model's\n",
    "    suggestion for a given tag matches any existing tags for the same asset).\n",
    "    \"\"\"\n",
    "    \n",
    "    rand = random.randint(0, len(test_dictionary) - 1)\n",
    "    keylist = list(test_dictionary.keys())\n",
    "    key = keylist[rand]\n",
    "    suggestions = test_dictionary[key]\n",
    "#     print(key, sugestions)\n",
    "    matches = 0\n",
    "    for suggestion in suggestions:\n",
    "        for key in keylist:\n",
    "            if suggestion == key:\n",
    "#                 print(\"MATCH!\", suggestion,  key)\n",
    "                return(\"MATCH\")\n",
    "    return(\"NO MATCH\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get embedding model and compute loss (for use in hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embedding model and compute loss (for use in hyperparameter tuning)\n",
    "for i in range(1,2):\n",
    "    print('epoch:', i)\n",
    "    start = time.time()\n",
    "    epochs = i\n",
    "    vec_size = 10\n",
    "    window = 5\n",
    "    vec_model = w2v_model.retrieve_model_no_id(epochs, vec_size, window)\n",
    "        \n",
    "#     vec_model = models.Word2Vec(test_df.values.tolist(), vector_size=vec_size, window=window, min_count=1, workers=4, compute_loss = True, epochs = epochs)\n",
    "#     end = time.time()\n",
    "    loss = vec_model.get_latest_training_loss()\n",
    "    # perplexity = 2**loss\n",
    "    print('loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile the set of tags for each asset. For each of those tags, we then get  a list of the most similar tags based on the W2V model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##to do: Make this a function with a parameter for each type of model\n",
    "\n",
    "# get lemmatized tag df with 1 row per asset and each tag in a separate column, covert to list of lists\n",
    "test_df = w2v_model.retrieve_expanded_query()\n",
    "# test_df = df_for_model\n",
    "test_vals = test_df.values[0:1000]\n",
    "# test_vals = test_df[0:1000]\n",
    "\n",
    "\n",
    "#use top_matches method to create a dictionary of related tags suggested by embedding model\n",
    "asset_dicts = []\n",
    "start = time.time()\n",
    "for i in range(len(test_vals)):\n",
    "#     print(\"remaining:\", len(test_vals) - i)\n",
    "    test_list = test_vals[i][test_vals[i] != None]\n",
    "#     rate.append(test_list)\n",
    "# #     print(test_list)\n",
    "    top_matches = get_top_matches(vec_model, test_list)\n",
    "    asset_dicts.append(top_matches)\n",
    "# #     str(test_list)\n",
    "end = time.time()\n",
    "print(\"elapsed:\", end - start)\n",
    "# asset_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of dictionaries where each key is a tag for that asset and each set of values is a list of potential suggestions based on the W2V embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asset_dicts[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asset_dicts[0].values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Suggestion Test    \n",
    "We test the effectiveness of this suggestion set by selecting a random tag from each asset and seeing if it matches any other tag assigned to that asset. In other words, if one key matches one of another key's values.    \n",
    "    \n",
    "to do: (Consider averaging this over a few iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use valid_prediction method to determine useful suggestions\n",
    "asset_results = []\n",
    "for i in asset_dicts:\n",
    "#     print(valid_prediction(i), i.keys())\n",
    "    asset_results.append(valid_prediction(i))\n",
    "print(\"rate of valid suggestions:\", asset_results.count(\"MATCH\")/len(asset_results))\n",
    "# asset_results.count(\"MATCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: LANGUAGE MODEL    \n",
    "     \n",
    "code credit: https://github.com/datasci-w266/2021-summer-main/tree/master/materials/simple_lm   \n",
    "\n",
    "We use a simple trigram model to see if that offers increased suggestion quality, on the assumption that tags will frequently in close context with simialr tags (ie, attached to the same asset).\n",
    "\n",
    "In reality, we found a much lower rate of useful suggestions (0.45) as compared to the simple W2V embedding model (0.75). We attempted to improve our trigram model by alphabetizing each tag list prior to training, in the hope that this would further emphasize relationships between related tags. This approach yielded an even lower valid suggestion rate (0.05). {why?}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_query = w2v_model.lm_retrieve_query()\n",
    "wordlist = get_query['cn'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_counter(c):\n",
    "    \"\"\"Given a dictionary of <item, counts>, return <item, fraction>.\"\"\"\n",
    "    total = sum(c.values())\n",
    "    return {w:float(c[w])/total for w in c}\n",
    "\n",
    "class SimpleTrigramLM(object):\n",
    "    def __init__(self, words):\n",
    "        \"\"\"Build our simple trigram model.\"\"\"\n",
    "        # Raw trigram counts over the corpus. \n",
    "        # c(w | w_1 w_2) = self.counts[(w_2,w_1)][w]\n",
    "        self.counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "    \n",
    "        # Iterate through the word stream once.\n",
    "        w_1, w_2 = None, None\n",
    "        for word in words:\n",
    "            if w_1 is not None and w_2 is not None:\n",
    "                # Increment trigram count.\n",
    "                self.counts[(w_2,w_1)][word] += 1\n",
    "            # Shift context along the stream of words.\n",
    "            w_2 = w_1\n",
    "            w_1 = word\n",
    "            \n",
    "        # Normalize so that for each context we have a valid probability\n",
    "        # distribution (i.e. adds up to 1.0) of possible next tokens.\n",
    "        self.probas = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "        for context, ctr in self.counts.items():\n",
    "            self.probas[context] = normalize_counter(ctr)\n",
    "            \n",
    "    def next_word_proba(self, word, seq):\n",
    "        \"\"\"Compute p(word | seq)\"\"\"\n",
    "        context = tuple(seq[-2:])  # last two words\n",
    "        return self.probas[context].get(word, 0.0)\n",
    "    \n",
    "    def predict_next(self, seq):\n",
    "        \"\"\"Sample a word from the conditional distribution.\"\"\"\n",
    "        context = tuple(seq[-2:])  # last two words\n",
    "        pc = self.probas[context]  # conditional distribution\n",
    "        words, probs = zip(*pc.items())  # convert to list\n",
    "        return np.random.choice(words, p=probs)\n",
    "    \n",
    "    def score_seq(self, seq, verbose=False):\n",
    "        \"\"\"Compute log probability (base 2) of the given sequence.\"\"\"\n",
    "        score = 0.0\n",
    "        count = 0\n",
    "        # Start at third word, since we need a full context.\n",
    "        for i in range(2, len(seq)):\n",
    "            if (seq[i] == \"<s>\" or seq[i] == \"</s>\"):\n",
    "                continue  # Don't count special tokens in score.\n",
    "            s = np.log2(self.next_word_proba(seq[i], seq[i-2:i]))\n",
    "            score += s\n",
    "            count += 1\n",
    "            # DEBUG\n",
    "            if verbose:\n",
    "                print(\"log P({:s} | {:s}) = {.03f}\".format(seq[i], \" \".join(seq[i-2:i]), s))\n",
    "        return score, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Word processing functions\n",
    "def canonicalize_digits(word):\n",
    "    if any([c.isalpha() for c in word]): return word\n",
    "    word = re.sub(\"\\d\", \"DG\", word)\n",
    "    if word.startswith(\"DG\"):\n",
    "        word = word.replace(\",\", \"\") # remove thousands separator\n",
    "    return word\n",
    "\n",
    "def canonicalize_word(word, wordset=None, digits=True):\n",
    "    word = word.lower()\n",
    "    if digits:\n",
    "        if (wordset != None) and (word in wordset): return word\n",
    "        word = canonicalize_digits(word) # try to canonicalize numbers\n",
    "    if (wordset == None) or (word in wordset):\n",
    "        return word\n",
    "    else:\n",
    "        return constants.UNK_TOKEN\n",
    "\n",
    "def canonicalize_words(words, **kw):\n",
    "    return [canonicalize_word(word, **kw) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_query = w2v_model.lm_retrieve_query()\n",
    "# get_query = w2v_model.retrieve_query()\n",
    "\n",
    "wordlist = get_query['cn'].tolist()\n",
    "# wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphabetized version\n",
    "import pandas as pd\n",
    "alpha_get_query = get_query[0:1000]\n",
    "v = np.sort(alpha_get_query.cn.str.split(',', expand=True).fillna(''), axis=1)\n",
    "df = pd.DataFrame(v).agg(','.join, 1).str.strip(',').str.lstrip()\n",
    "\n",
    "# wordlist = df.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=0.8\n",
    "sentences = np.array(list(wordlist), dtype=object)\n",
    "fmt = (len(sentences), sum(map(len, sentences)))\n",
    "print(\"Loaded {:,} sentences ({:g} tokens)\".format(*fmt))\n",
    "\n",
    "\n",
    "rng = np.random.RandomState()\n",
    "rng.shuffle(sentences)  # in-place\n",
    "split_idx = int(split * len(sentences))\n",
    "train_sents = sentences[:split_idx]\n",
    "test_sents = sentences[split_idx:]\n",
    "\n",
    "for l in range(len(train_sents)):\n",
    "    train_sents[l] = train_sents[l].split(\", \")\n",
    "for l in range(len(test_sents)):\n",
    "    test_sents[l] = test_sents[l].split(\", \")\n",
    "# train_sents = train_sents.split(\",\")\n",
    "# test_sents = test_sents.split(\",\")\n",
    "\n",
    "fmt = (len(train_sents), sum(map(len, train_sents)))\n",
    "print(\"Training set: {:,} sentences ({:,} tokens)\".format(*fmt))\n",
    "fmt = (len(test_sents), sum(map(len, test_sents)))\n",
    "print(\"Test set: {:,} sentences ({:,} tokens)\".format(*fmt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word processing functions\n",
    "def canonicalize_digits(word):\n",
    "    if any([c.isalpha() for c in word]): return word\n",
    "    word = re.sub(\"\\d\", \"DG\", word)\n",
    "    if word.startswith(\"DG\"):\n",
    "        word = word.replace(\",\", \"\") # remove thousands separator\n",
    "    return word\n",
    "\n",
    "def canonicalize_word(word, wordset=None, digits=True):\n",
    "    word = word.lower()\n",
    "    if digits:\n",
    "        if (wordset != None) and (word in wordset): return word\n",
    "        word = canonicalize_digits(word) # try to canonicalize numbers\n",
    "    if (wordset == None) or (word in wordset):\n",
    "        return word\n",
    "    else:\n",
    "        return constants.UNK_TOKEN\n",
    "\n",
    "def canonicalize_words(words, **kw):\n",
    "    return [canonicalize_word(word, **kw) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9232391/9232391 [00:28<00:00, 325106.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set vocabulary: 39563 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = vocabulary.Vocabulary(canonicalize_word(w) for w in ProgressBar(utils.flatten(train_sents)))\n",
    "print(\"Train set vocabulary: %d words\" % vocab.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sents_to_tokens(sents):\n",
    "    \"\"\"Returns an flattened list of the words in the sentences, with padding for a trigram model.\"\"\"\n",
    "    padded_sentences = ([\"<s>\", \"<s>\"] + s + [\"</s>\"] for s in sents)\n",
    "    # This will canonicalize words, and replace anything not in vocab with <unk>\n",
    "    return np.array([utils.canonicalize_word(w, wordset=vocab.wordset) \n",
    "                     for w in ProgressBar(utils.flatten(padded_sentences))], dtype=object)\n",
    "\n",
    "train_tokens = sents_to_tokens(train_sents)]z_\n",
    "test_tokens = sents_to_tokens(test_sents)\n",
    "\n",
    "t0 = time.time()\n",
    "print(\"Building trigram LM...\",)\n",
    "lm = SimpleTrigramLM(train_tokens)\n",
    "print(\"done in %.02f s\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens[0:200]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Sample Predictions    \n",
    "When we task our model with generating predictions, we do see some relevance in the results. We quantify this later using our Functional Suggestion Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_predictions(l_model, tag, max_length):\n",
    "        seq = [\"<s>\", tag]\n",
    "        for i in range(max_length):\n",
    "            try:\n",
    "                    seq.append(l_model.predict_next(seq))\n",
    "            except ValueError:\n",
    "                seq.append('nodata_nodata')\n",
    "        seq = seq[2:]\n",
    "        return seq\n",
    "\n",
    "lm_predictions(lm, 'blue', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring  \n",
    "We check the perplexity and then employ the same functional suggestion test that we used for the W2V embeddings.    \n",
    "We see that the rate of valid predictions for the LM is actually much lower than that of the simple embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_data, num_real_tokens = lm.score_seq(train_tokens)\n",
    "print(\"Train perplexity: {:.02f}\".format(2**(-1*log_p_data/num_real_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for i in asset_dicts:\n",
    "    lengths.append(len(i.values()))\n",
    "np.average(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_get_top_matches(l_model, test_list):\n",
    "    \"\"\"\n",
    "    Given a language model and list of tags, gets most similar results.\n",
    "    Runs on one row (asset) at a time.\n",
    "    \"\"\"\n",
    "#     ref_list = []\n",
    "    matches = {}\n",
    "#     not_found = 0\n",
    "    for lstring in test_list:\n",
    "        tagset = []\n",
    "        try:\n",
    "            match = lm_predictions(lm, lstring, 15)\n",
    "            for tag in range(len(match)):\n",
    "#             for tag in range(2):\n",
    "                tagset.append(match[tag])\n",
    "\n",
    "# #             ref_list.append(tagset)\n",
    "            matches[lstring] = tagset\n",
    "        except KeyError:\n",
    "    #         print(ls, ' : ','NOT_FOUND')\n",
    "            pass\n",
    "#     print(\"Not found\", not_found)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##to do: Make this a function with a parameter for each type of model\n",
    "\n",
    "# get lemmatized tag df with 1 row per asset and each tag in a separate column, covert to list of lists\n",
    "test_df = w2v_model.retrieve_expanded_query()\n",
    "lm_test_vals = test_df.values[0:100]\n",
    "  \n",
    "#use top_matches method to create a dictionary of related tags suggested by embedding model\n",
    "lm_asset_dicts = []\n",
    "start = time.time()\n",
    "for i in range(len(lm_test_vals)):\n",
    "#     print(\"remaining:\", len(test_vals) - i)\n",
    "    lm_test_list = lm_test_vals[i][lm_test_vals[i] != None]\n",
    "#     rate.append(test_list)\n",
    "# #     print(test_list)\n",
    "    lm_top_matches = lm_get_top_matches(lm, lm_test_list)\n",
    "    lm_asset_dicts.append(lm_top_matches)\n",
    "# #     str(test_list)\n",
    "end = time.time()\n",
    "print(\"elapsed:\", end - start)\n",
    "# lm_asset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use valid_prediction method to determine useful suggestions\n",
    "lm_asset_results = []\n",
    "for i in lm_asset_dicts:\n",
    "#     print(valid_prediction(i), i.keys())\n",
    "    lm_asset_results.append(valid_prediction(i))\n",
    "print(\"Rate of valid suggestions:\", lm_asset_results.count(\"MATCH\")/len(lm_asset_results))\n",
    "# asset_results.count(\"MATCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3. BERT ATTEMPT  \n",
    "Given that our corpus is full of unusual terms and that our \"sentences\" are order-agnostic, BERT's pre-trained bi-directional nature makes it a counterintuitive choice. We propose a novel application, however, in which BERT is fine-tuned on our tag corpus. As in our LM test, we order tags in our corpus alphabetically to impose a sense of word order significance.\n",
    "        \n",
    "BERT plan:    \n",
    "1. create version of reconstructed_assets with rare tags removed, each set of tags alphabetized   \n",
    "2. fine-tune BERT on that <<---- this is where I'm stuck :( \n",
    "3. give BERT an unedited tag list for a given asset, with rare tags changed to [MASK]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code credit: https://gist.github.com/yuchenlin/a2f42d3c4378ed7b83de65c7a2222eb2\n",
    "# !pip install torchvision \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "def predict_masked_sent(text, top_k=5):\n",
    "    # Tokenize input\n",
    "    text = \"[CLS] %s [SEP]\"%text\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    masked_index = tokenized_text.index(\"[MASK]\")\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    # tokens_tensor = tokens_tensor.to('cuda')    # if you have gpu\n",
    "\n",
    "    # Predict all tokens\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "    probs = torch.nn.functional.softmax(predictions[0, masked_index], dim=-1)\n",
    "    top_k_weights, top_k_indices = torch.topk(probs, top_k, sorted=True)\n",
    "\n",
    "    for i, pred_idx in enumerate(top_k_indices):\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "        token_weight = top_k_weights[i]\n",
    "        print(\"[MASK]: '%s'\"%predicted_token, \" | weights:\", float(token_weight))\n",
    "\n",
    "        \n",
    "predict_masked_sent(\"BERT is [MASK] at this.\", top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla BERT given a test tag sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masked_sent(\"[MASK], 'Lighting', 'Arts Culture and Entertainment', 'Light Fixture', 'Water', 'Chandelier', 'Ceiling Fixture', 'Ceiling', 'BFfulltakes_FTP'\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  TEST WITH FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4. SUGGESTION FUNCTION IMPLEMENTATION   \n",
    "We loop through the list of assets and attempt to offer alternative tags for any rare tags that we enconter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the simple W2V embeddings for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check = w2v_model.lm_retrieve_expanded_query()\n",
    "to_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:  \n",
    "add more iterations to feed result list of tags back into function for further refinement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#given a list of tags, identify those that are rare and provide suggested replacements\n",
    "def get_candidates(tag_list):\n",
    "    start = time.time()\n",
    "    lemma_dict = w2v_model.lemma_map()\n",
    "    lemma_common_tags = []\n",
    "    lemma_rare_tags = []\n",
    "    candidates = []\n",
    "#     cand_list = []\n",
    "    for tag in tag_list:\n",
    "        try:\n",
    "            if w2v_model.is_not_rare(lemma_dict[tag]):\n",
    "                lemma_common_tags.append(lemma_dict[tag])\n",
    "                continue\n",
    "            else:\n",
    "                lemma_rare_tags.append(lemma_dict[tag])\n",
    "        except KeyError:\n",
    "            if w2v_model.is_not_rare(tag):\n",
    "                continue\n",
    "        try:    \n",
    "            if tag is not None:\n",
    "                candidate = get_top_matches(vec_model, ['', lemma_dict[tag]])\n",
    "    #             print('tag: ', tag, '\\nsuggestions:', candidates.values(),'\\n')\n",
    "#                 cand_list.append(candidate)\n",
    "                candidates.append(candidate.values())\n",
    "        except KeyError:\n",
    "            pass\n",
    "    flat = list(chain(*candidates))\n",
    "    flatter = list(chain(*flat)) \n",
    "#     print('lemma common tags: ', lemma_common_tags, '\\nlemma rare tags: ', lemma_rare_tags)      \n",
    "    return flatter\n",
    "\n",
    "def suggest_better_tags(list_of_tags):\n",
    "    tag_candidates = get_candidates(list_of_tags)\n",
    "    tag_candidates = [w2v_model.delete_rare(tc) for tc in tag_candidates]\n",
    "    tag_candidates = [tag for tag in tag_candidates if tag != \"\"]\n",
    "    \n",
    "    return tag_candidates\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "# list_of_tags = to_check.values[2]\n",
    "# list_of_tags = [\"Saw\"]\n",
    "# zzz = suggest_better_tags(list_of_tags, 1)\n",
    "# zzz\n",
    "# # print(lemma_dict(list_of_tags), zzz)\n",
    "# # yyy = get_candidates(list_of_tags)\n",
    "# # yyy\n",
    "# list_of_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gather suggestions for every tag and concatenate those into a\n",
    "single suggestion list.    \n",
    "Then we discard uncommon (rare) suggestions and identify suggestions that were already tags for the given asset (duplicates).     \n",
    "The final list of suggested tags then consists only of common tags that are not already applied to the asset.   \n",
    "We also track the duplicates so they can be used to validate the usability of our suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For each asset (row), gather suggestions for every tag and concatenate those into a\n",
    "single suggestion list. Then discard uncommon (rare) suggestions and identify\n",
    "suggestions that were already tags for the given asset (duplicates). The final list of suggested tags\n",
    "is then only common tags that are not already applied to the asset.\n",
    "\n",
    "This function also tracks the duplicates so they can be used to validate the usability of our suggestions.\n",
    "'''\n",
    "\n",
    "def get_real_suggestions(existing_tags):\n",
    "    #GIVE THIS FUNCTION AT LEAST TWO LISTS OF TAGS OR A LIST WRAPPED IN AN EMPTY LIST\n",
    "    start = time.time()\n",
    "    count = len(existing_tags)\n",
    "    \n",
    "    all_live_suggestions = []\n",
    "    all_new_suggestions = []\n",
    "    all_dupe_suggestions = []\n",
    "    all_weighted = []\n",
    "\n",
    "    lemma_dict = w2v_model.lemma_map()\n",
    "    for i in range(count):\n",
    "        live_tags = existing_tags[i]\n",
    "#         print(\"tags in \\n\", live_tags, '\\n')\n",
    "        live_suggestions = suggest_better_tags(live_tags)\n",
    "        all_live_suggestions.append(live_suggestions)\n",
    "    #     print(\"all suggestions \\n\", live_suggestions, '\\n')\n",
    "        new_suggestions = []\n",
    "        dupe_suggestions = []\n",
    "        for sug in live_suggestions:\n",
    "            for tag in live_tags:\n",
    "                if sug == lemma_dict.get(tag):\n",
    "                    if sug not in dupe_suggestions:\n",
    "                        dupe_suggestions.append(sug)\n",
    "                    continue              \n",
    "            if sug not in dupe_suggestions:\n",
    "                new_suggestions.append(sug)\n",
    "        counts = collections.Counter(new_suggestions)\n",
    "        weighted = counts.most_common()\n",
    "        all_weighted.append(weighted)\n",
    "        \n",
    "        all_dupe_suggestions.append(dupe_suggestions)\n",
    "        all_new_suggestions.append(new_suggestions)\n",
    "#         counts = collections.Counter(all_new_suggestions)\n",
    "#         weigthed = counts.most_common()\n",
    "    return [all_live_suggestions, all_dupe_suggestions, all_new_suggestions, all_weighted]\n",
    "test_check = to_check.values[0:100]\n",
    "\n",
    "start = time.time()\n",
    "real_suggestions = get_real_suggestions(test_check)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function returns a batch of new legitimate suggested tags for each asset (ideally), sorted by frequency.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(real_suggestions[0])):\n",
    "    print('\\n\\n Asset', i, '\\n\\nORIGINAL TAG LIST: \\n', test_check[i], '\\nSUGGESTIONS: \\n', real_suggestions[0][i], '\\nDUPLICATES: \\n', real_suggestions[1][i], '\\nLEGITIMATE SUGGESTIONS:  \\n', real_suggestions[2][i],  '\\nBY WEIGHT:  \\n', real_suggestions[3][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: scoring/stats, etc   \n",
    "We see at least one valid, common suggestion (defined as a tag that was actually attached by a user in our initial data set) for approx 80% of assets. (based on 1000 assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = real_suggestions[1]\n",
    "# def condition(x): return len(x) == 0\n",
    "output = [idx for idx, element in enumerate(dupes) if len(element) > 0]\n",
    "len(output)/len(real_suggestions[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function suggests an average of approx 10 common tags per asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unique = real_suggestions[3]\n",
    "new_unique_lengths = []\n",
    "for nu in new_unique:\n",
    "    l = len(nu)\n",
    "    new_unique_lengths.append(l)\n",
    "sum(new_unique_lengths)/len(new_unique_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random list of common tags\n",
    "\n",
    "rand_tags = w2v_model.retrieve_rare(3)\n",
    "rand_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_end = time.time()\n",
    "print(nb_end - nb_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
